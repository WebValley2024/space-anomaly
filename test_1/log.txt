AnomalyTransformer(
  (embedding): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (tokenConv): Conv1d(8, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)
    )
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-2): 3 x EncoderLayer(
        (attention): AttentionLayer(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (inner_attention): AnomalyAttention(
            (dropout): Dropout(p=0, inplace=False)
          )
          (query_projection): Linear(in_features=512, out_features=512, bias=True)
          (key_projection): Linear(in_features=512, out_features=512, bias=True)
          (value_projection): Linear(in_features=512, out_features=512, bias=True)
          (sigma_projection): Linear(in_features=512, out_features=8, bias=True)
          (out_projection): Linear(in_features=512, out_features=512, bias=True)
        )
        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (projection): Linear(in_features=512, out_features=8, bias=True)
)


loss: [-37.42578432036609, -44.89901787672586, -46.4519299607936, -46.72161404679461, -46.94226540976423, -47.084239091330424, -47.22646618664749, -47.3408827277703, -47.513055305170816, -47.653873691713905, -47.76994374903237, -47.91286533634837, -48.01531779281492, -48.095690983097725, -48.18076195755625, -48.23762254792501, -48.293901691591834, -48.34360888721497, -48.37724453065454, -48.42285770323218, -48.4319756980834, -48.45981241241703, -48.49271138509115, -48.525787601626014, -48.52644980826029, -48.47083853124603, -48.49694148117934, -48.51352502466217, -48.530726983295224, -48.51319717779392, -48.57525761922201, -48.57683997425607, -48.59614438933085, -48.616644851560515, -48.62544963805656, -48.587458075546635, -48.632300555221434, -48.64578951083548, -48.64278920491537, -48.64193911668731, -48.6656720851495, -48.67518420335723, -48.67417281236106, -48.687348311509545, -48.69548540192891, -48.70014624867013, -48.71155513980524, -48.718647623449804, -48.705391581465555, -48.60763531196408, -48.69647229202395, -48.70278902751644, -48.725807407038, -48.73347011038928, -48.748814838688546, -48.747776775825315, -48.75577632004653, -48.760822668308165, -48.744857260851354, -48.74965987166738, -48.76817625712573, -48.74746059014545, -48.7663318975185, -48.752958499319185, -48.76849002372928, -48.794828957658474, -48.7966365969278, -48.804332857209495, -48.797629503699824, -48.80385884230699, -48.78628509025263, -48.79464817822464, -48.820829934220974, -48.828354254001525, -48.83441438132185, -48.83983999733033, -48.83947961698703, -48.82943983000468, -48.81488986131622, -48.83803170677123, -48.83323849313627, -48.47977349816299, -48.70115807385949, -48.400302980004284, -48.48820889480715, -48.72115831452657, -48.72617978972148, -48.738753838267755, -48.74596448448615, -48.80762165348704, -48.81226916429473, -48.828122301799496, -48.83945241788538, -48.823883769958, -48.73142574279289, -48.62766664396457, -48.776472417319695, -48.809649769852804, -48.81222335691375, -48.67082943179743]

time: 0.4230358600616455

ID : 1
lr : 0.0001
num_epochs : 100
k : 3
win_size : 50
input_c : 8
output_c : 8
batch_size : 16
dataset : space
mode : train
data_path : dataset/space
model_save_path : checkpoints
step : 50
test_model : None
e_layers : 3
n_heads : 8
d_ff : 512
d_model : 512
dropout : 0
quantile_treshold : 0.999937
